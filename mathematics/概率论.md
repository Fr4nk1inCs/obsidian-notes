#数学 #概率论 #统计

# 事件与概率

## 随机现象和随机事件

- **随机现象**: 自然界中的客观现象, 当人们观测它时, 所得结果不能预先确定, 而仅仅是多种可能结果之一. 如 "明天是否下雨".
- **随机试验**: 一个实验称为随机试验, 若该试验满足以下条件:
  - 在相同条件下课重复进行;
  - 所有的试验结果是明确可知的, 结果至少有两个;
  - 每次试验恰好出现这些结果中的一个, 但在试验之前无法预知该结果.

### 基本概念

- **样本点** ($w$): 基本试验结果
- **样本空间** ($\Omega$): 试验 $S$ 所有的样本点 $w$ 构成的集合, 即 $\Omega=\{w\vert w\text{是试验的样本点}\}$.
  - 样本空间可以有限, 也可以无限 (可数和不可数)
- **随机事件**: 样本空间 $\Omega$ 的子集 $A\subset\Omega$ 是事件.
  - 如果 $w\in A$, 则称事件 $A$ 发生, 否则称 $A$ 不发生.
  - **基本事件**: 单个样本点构成的事件
  - **复杂事件**: 由一个或若干个基本事件组成
  - 特殊事件: 必然事件 $\Omega$, 不可能事件 $\varnothing$

事件的运算符号和集合的运算符号是相同的, 运算规律也一致, 集合的运算详见各个代数学教程, 这里不再赘述.

用 $\lvert A\rvert$ 表示事件 $A$ 的样本点个数, 用 $\lvert\Omega\rvert$ 表示样本空间 $\Omega$ 中的样本点个数.

## 古典概型

- **概率**: 设 $\Omega$ 是样本空间. 对于 $\Omega$ 的事件 $A\subset\Omega$, 我们用 $[0,1]$ 中的数 $P(A)$ 表示 $A$ 发生的可能性的大小, 称 $P(A)$ 是事件 $A$ 发生的概率, 简称为 $A$ 的概率.
  - 按照以上原则, 如果事件 $A,B$ 发生的可能性相同, 则有 $P(A)=P(B)$.
- **古典概型**: 试验结果有限, 等可能性
  - 一个试验 $S$ 有有限个试验结果 $\{w_1, w_2, \cdots, w_n\}$.
  - 找不到理由认为一个试验结果比另一个试验结果更易于发生.
- **古典概率**: 设试验 $S$ 的样本空间 $\Omega$ 是有限集合, $A\subset\Omega$. 如果 $\Omega$ 的每个样本点发生的可能性相同, 则称
  $$
  P(A)=\frac{\lvert A\rvert}{\lvert\Omega\rvert}
  $$
  为试验 $S$ 下 $A$ 发生的概率, 简称为事件 $A$ 的概率.

### 一些计数模式

- 排列组合
  - 从 $n$ 个不同的元素中有放回地每次抽取一个, 依次抽取 $m$ 个排成一列, 可以得到 $n^m$ 个不同的排列. 当随机抽取时, 得到的不同排列是等可能的, $p=\frac1{n^m}$.
  - 从 $n$ 个不同的元素中无放回地抽取 $m$ 个元素排成一列时, 可以得到 $\mathrm A^m_n=\frac{n!}{(n-m)!}$ 个不同的排列. 当随机抽取和排列时, 得到的不同排列是等可能的.
  - 从 $n$ 个不同的元素中无放回地抽取 $m$ 个元素, 不论次序地组成一组, 可以得到 $\mathrm C^m_n=\frac{n!}{m!(n-m)!}$ 个不同的组合. 当随机抽取时, 得到的不同组合是等可能的.
  - 将 $n$ 个不同的元素分成有次序的 $k$ 组, 不考虑每组中元素的次序, 第 $i(1\le i\le k)$ 组恰好有 $n_i$ 个元素的不同结果数是 $\frac{n!}{\prod^k_{i=1}n_i!}$, 当随机分组时, 得到的不同结果是等可能的.
- 不相邻问题: 现有 $A,B$ 两类不同的个体做全排列, 使得 $B$ 类中个体在排列中互不相邻, 求排列数.
  - 先将 $A$ 类个体做全排列, 然后在 $A$ 类排列的每相邻两个个体之间插入一个空位, 在 $A$ 类个体的最左侧和最右侧各插入一个空位, 再在这些空位中选取适当个数的空位来排列 $B$ 类个体.

## 概率的公理化

设 $\Omega$ 是试验 $S$ 的样本空间, 事件必须是 $\Omega$ 的子集, 且满足以下条件:

- $\Omega$ 和空集 $\varnothing$ 是事件
- 事件经过有限次集合运算得到的集合是事件
- 如果 $A_j$ 是事件, 则 $\bigcup_{j=1}^\infty A_j$ 是事件

对于事件 $A$, 概率 $P(A)$ 是表示 $A$ 发生的可能性的大小的实数, 必须满足以下三个条件 (概率的**公理化条件**):

- **非负性**: $\forall\text{事件}A, P(A)\ge0$
- **完全性**: $P(\Omega)=1, P(\varnothing)=0$
- **可加性**: 对于互不相容的事件 $A_1, A_2, \cdots$, 有
  $$
  P\left(\bigcup_{j=1}^n A_j\right)=\sum_{j=1}^n P(A_j), P\left(\bigcup_{j=1}^\infty A_j\right)=\sum_{j=1}^\infty P(A_j)
  $$

> 不满足公理化条件的 $P$ 不是概率

<font color=green>定理 1.3.1</font> 概率 $P$ 有以下的性质

1. $P(\bar A) = 1-P(A)\le 1$
2. 单调性: $B\subset A\Rightarrow P(B)\le P(A)$
3. 次可加性: 对于事件 $A_1, A_2, \cdots$, 有
   $$
   P\left(\bigcup_{j=1}^n A_j\right)\le\sum_{j=1}^n P(A_j), P\left(\bigcup_{j=1}^\infty A_j\right)\le\sum_{j=1}^\infty P(A_j)
   $$

如果用 $\mathcal F\subset\mathscr P(\Omega)$ 表示样本空间 $\Omega$ 的事件的全体, $P$ 表示概率, 则 $(\Omega,\mathcal F, P)$ 为概率空间.

古典概型的两个条件往往不能满足, 此时如何定义概率?常用的一种方法是把含有事件 $A$ 的随机试验独立重复做 $N$ 次 (Bernoulli 试验), 称

$$
f_N=\frac{N \text{次试验中} A \text{发生的次数}}{N}
$$

是 $N$ 次独立重复试验中, 事件 $A$ 发生的**频率**. 当 $N$ 越来越大时, 频率会在某个值 $P(A)$ 附近波动, 且波动越来越小, 这个值 $P(A)$ 就定义为事件 A 的概率.

## 几何概型

- 古典概型: 试验结果有限, 等可能性
- 几何概型: 取消 "试验结果有限", 对"等可能性" 作不同假设: 等长度 (面积, 体积), 等概率

## 加法公式

$$
P(A\cup B)=P(A)+P(B)-P(AB)
$$

$$
P\left(\bigcup_{j=1}^3A_j\right)=\sum^3_{j=1}P(A_j)-\sum_{1\le i< j\le3}P(A_iA_j)+P(A_1A_2A_3)
$$

## 事件的独立性

<font color = yellow>定义 1.6.1</font> 如果 $P(AB)=P(A)P(B)$, 则称 $A,B$ 相互独立, 简称为**独立**.

<font color=green>定理 1.6.1</font> $A,B$ 独立当且仅当 $\bar A,B$ 独立.

<font color = yellow>定义 1.6.2</font>

1. 称 $A_1, A_2, \cdots, A_n$ 相互独立, 如果对任何 $1\le j_1<j_2<\cdots<j_k\le n$, 有 $P\left(\bigcap_{i=1}^{k}A_{j_i}\right)=\prod_{i=1}^{k}P(A_{j_i})$
2. 称 $A_1, A_2, \cdots$ 相互独立, 如果对任意的 $n\ge2$, 事件 $A_1, A_2, \cdots, A_n$ 相互独立. 这时也称 $\{A_n\}$ 为**独立事件列**.

> $A,B,C$ 两两独立不能保证它们相互独立

<font color=green>定理 1.6.2</font> 设 $A_1, A_2, \cdots, A_n$ 相互独立, 则

1. 对任何 $1\le j_1<j_2<\cdots<j_k\le n$, $A_{j_1}, A_{j_2},\cdots, A_{j_k}$ 相互独立.
2. 用 $B_j$ 表示 $A_j$ 或 $\bar A_j$, 则 $B_1, B_2, \cdots, B_n$ 相互独立
3. $(A_1 A_2), A_3, \cdots, A_n$ 相互独立
4. $(A_1\cup A_2), A_3, \cdots, A_n$ 相互独立

## 条件概率与乘法公式

### 条件概率

^c68750

设 $A,B$ 是事件, 用 $P(B\vert A)$ 表示已知 $A$ 发生的条件下, $B$ 发生的条件概率, 简称为**条件概率**, 计算公式如下:

$$
\text{if } P(A)>0,P(B\vert A)=\frac{P(AB)}{P(A)}
$$

### 乘法公式

设 $P(A)>0, P\left(\bigcap^{n-1}_{j=1}A_j\right)>0$, 则

1. $P(AB)=P(A)P(B\vert A)$
2. $P\left(\bigcap^{n}_{j=1}A_j\right)=P(A_1)\prod_{i=1}^{n-1}P\left(A_{i+1}\left\vert\bigcap^{i}_{j=1}A_j\right.\right)$

> 若 $A,B$ 独立, 则 $P(B\vert A)=P(B)$

## 全概率公式与贝叶斯公式

### 全概率公式

对于任何事件 $A,B$, 利用概率的可加性, 有 $P(B)=P(AB+\bar AB)=P(AB)+P(\bar AB)$, 再利用乘法公式得到**全概率公式**:

$$
P(B)=P(A)P(B\vert A)+P(\bar A)P(B\vert\bar A)
$$

稍做推广, 有:

<font color=green>全概率公式</font> 如果事件 $A_1, A_2, \cdots, A_n$ 互不相容, $B\subset\bigcup^n_{j=1}A_j$, 则

$$
P(B)=\sum_{j=1}^n P(A_j)P(B\vert A_j)
$$

> 如果事件 $A_1, A_2, \cdots, A_n$ 互不相容且 $\bigcup^n_{j=1}A_j=\Omega$, 则称 $A_1, A_2, \cdots, A_n$ 是**完备事件组**.

### 贝叶斯 (Bayes) 公式

对于事件 $A,B$, 当 $P(B)>0$, 利用条件概率公式有

$$
P(A\vert B)=\frac{P(AB)}{P(B)}=\frac{P(A)P(B\vert A)}{P(B)}
$$

对于 $P(B)$ 再利用全概率公式, 得到**贝叶斯公式**:

$$
P(A\vert B)=\frac{P(A)P(B\vert A)}{P(A)P(B\vert A)+P(\bar A)P(B\vert\bar A)}
$$

稍做推广, 有:

<font color=green>贝叶斯公式</font> 如果事件 $A_1, A_2, \cdots, A_n$ 互不相容, $B\subset\bigcup^n_{j=1}A_j$, 则

$$
P(A_j\vert B)=\frac{P(A_j)P(B\vert A_j)}{\sum_{i=1}^nP(A_i)P(B\vert A_i)}
$$

---

# 随机变量及概率分布

## 随机变量的基本概念

> 概率论是从数量上来研究随机现象内在规律性的, 为了更方便有力的研究随机现象, 就要用数学分析的方法来研究, 因此为了便于数学上的推导和计算, 就需将任意的随机事件数量化. 当把一些非数量表示的随机事件用数字来表示时, 就建立起了随机变量的概念.

### 随机变量

设 $S$ 是随机试验, 其样本空间为 $\Omega$, 定义单射 $X(w):\Omega\to\mathbb R$ 为随机变量.

- 离散型: 随机变量所取的可能值是有限多个或无限可列个, 叫做离散型随机变量.
- 连续型: 随机变量所有可能取值连续地充满某个区间 (并有密度函数), 叫连续型随机变量.

### 概率分布函数

<font color = yellow>定义 2.1.1</font> 对随机变量 $X$, 称 $x$ 的函数 $F(x)\equiv P(X\le x), x\in \mathbb R$ 为 $X$ 的**概率分布函数**, 简称为**分布函数**.

概率分布函数有以下性质:

1. $F$ 是单调递增的右连续函数
2. $\lim_{x\to\infty}F(x)=F(\infty)=1, \lim_{x\to-\infty}F(x)=F(-\infty)=0$
3. $F$ 在点 $x$ 连续的充分必要条件是 $P(X=x)=0$

## 离散型随机变量及其分布律

### 离散型随机变量的分布律

离散型随机变量 $X$ 所有可能取的值为 $x_j(j=1,2,\cdots)$, $X$ 取各个可能值的概率 $P(X=x_j)$ 为 $p_j(j=1,2,\cdots)$, 则称 $\{p_j\}$ 为离散型随机变量 $X$ 的分布律, 也可以表示为

$$
X\sim\begin{pmatrix}x_1&x_2&\cdots&x_n&\cdots\\p_1&p_2&\cdots&p_n&\cdots\end{pmatrix}
$$

或

| $X$   | $x_1$ | $x_2$ | $\cdots$ | $x_n$ | $\cdots$ |
| ----- | ----- | ----- | -------- | ----- | -------- |
| $p_j$ | $p_1$ | $p_2$ | $\cdots$ | $p_n$ | $\cdots$ |

其中 $p_j$ 满足

1. $p_j\ge0$
2. $\sum_{j=1}^\infty p_j=1$

### 常见离散型随机变量的分布律

#### 两点分布

设随机变量 $X$ 只可能取 0 与 1 两个值, 它的分布律为

$$
X\sim\begin{pmatrix}0&1\\p&1-p\end{pmatrix}
$$

则称 $X$ 服从**两点分布**或 (0-1) 分布.

#### 二项分布 (Bernoulli 分布)

##### 重复独立试验

将试验 $S$ 重复进行 $n$ 次, 若各次试验的结果互不影响, 即每次试验结果出现的概率都不依赖于其它各次试验的结果, 则称这 $n$ 次试验是相互独立的, 或称为 $n$ 次重复独立试验.

##### n 重 Bernoulli 试验

- 若试验 $S$ 只有两个可能的结果 $A, \bar A$, 则称其为 Bernoulli 试验.
- 将 $S$ 独立地重复进行 $n$ 次, 则称这一串重复的独立实验为 $n$ 重 Bernoulli 试验

##### 二项分布

用 $X$ 表示 $n$ 重 Bernoulli 试验中事件 $A$ 发生的次数, 则 $X$ 所有可能的取值为 $0,1,2,\cdots,n$, 有

$$
p_j=P(X=j)=\begin{pmatrix}n\\j\end{pmatrix}p^j(1-p)^{n-j}
$$

得到 $X$ 的分布律为

$$
X\sim\begin{pmatrix}
0&1&\cdots&j&\cdots&n\\
(1-p)^n&np(1-p)^{n-1}&\cdots&\begin{pmatrix}n\\j\end{pmatrix}p^j(1-p)^{n-j}&\cdots&p^n
\end{pmatrix}
$$

称这样的分布为**二项分布**. 称 $X$ 服从参数为 $n,p$ 的二项分布, 记作 $X\sim B(n,p)$, 当 $n=1$ 时, 二项分布退化为两点分布.

##### 二项分布的 Poisson 逼近

<font color=green>Poisson 定理</font> 设 $\lambda>0$ 是常数, $n\in\mathbb Z^+$, 且 $\lambda=np$, 则对于任意取定的 $k\in\mathbb N$, 有

$$
\lim_{n\to\infty}\begin{pmatrix}n\\k\end{pmatrix}p^k(1-p)^{n-k}=\frac{\lambda^k}{k!}\exp(-\lambda)
$$

> 由 Poisson 定理, 若 $n$ 很大 $p$ 很小且 $\lambda=np$ 时, 有 $P(X=j)=\begin{pmatrix}n\\j\end{pmatrix}p^j(1-p)^{n-j}\approx\frac{\lambda^j}{j!}\exp(-\lambda)$, 其中一般要求 $n\ge20, p\le 0.05$.

#### Poisson 分布

设随机变量 $X$ 所有可能的取值为 $0,1,2,\cdots,n$, 而取各个值的概率为

$$
p_j=P(X=j)=\frac{\lambda^j}{j!}\exp(-\lambda)
$$

其中 $\lambda>0$ 是常数, 则称 $X$ 满足参数为 $\lambda$ 的 Poisson 分布, 记为 $X\sim P(\lambda)$.

> 当 $n\to\infty$ 是, 二项分布趋近于 Poisson 分布.

#### 几何分布

设随机变量 $X$ 所有可能的取值为 $1,2,\cdots,n$, 而取各个值的概率为

$$
p_j=P(X=j)=(1-p)^{k-1}p
$$

则称 $X$ 满足参数为 $p$ 的几何分布, 记为 $X\sim G(\lambda)$.

#### 超几何分布 (Hypergeometric 分布)

设随机变量 $X$ 所有可能的取值为 $0,1,2,\cdots,M$, 而取各个值的概率为

$$
p_j=P(X=j)=\frac{\begin{pmatrix}M\\j\end{pmatrix}\begin{pmatrix}N-M\\n-j\end{pmatrix}}{\begin{pmatrix}N\\n\end{pmatrix}}
$$

其中 $N,M,n$ 是常数, 则称 $X$ 满足参数为 $N,M,n$ 的超几何分布, 记为 $X\sim H(N,M,n)$.
注意上面约定: 对 $k<0$ 或 $k>n$, 有 $\begin{pmatrix}n\\k\end{pmatrix}=0$.

## 连续型随机变量

### 概率密度函数

<font color = yellow>定义 2.3.1</font> 设 $F(x)=P(X\le x)$ 是随机变量 $X$ 的分布函数, 如果有非负函数 $f(x)$ 使得

$$
F(x)=\int_{-\infty}^xf(s)\mathrm ds, \forall x\in\mathbb R
$$

则称 $f(x)$ 是 $X$ 或 $F(x)$ 的**概率密度**, 简称为**密度**.

> 容易看出, 当 $F(x)$ 有密度函数时, 其作为变上限的积分, 是连续函数. 所以当 $F(x)$ 不是连续函数时, $X$ 没有概率密度.

<font color=green>定理 2.3.1</font> 设 $X$ 的分布函数 $F(x)$ 连续, 且在任何有限区间 $(a,b)$ 中除去有限个点外有连续的导函数, 则

$$
f(x)=\begin{cases}
F'(x)&\text{if }F'(x)\text{ exists}\\
0&\text{otherwise}
\end{cases}
$$

是 $X$ 的概率密度.

设 $F(x)$ 是 $X$ 的密度函数, $f(x)$ 是概率密度. 对于任何常数 $a<b$ 和事件 $A\subset\mathbb R$, 有

$$
\begin{aligned}
&P(a<x\le b)=\int_{a}^{b}f(s)\mathrm ds\\
&P(A)=P(X\in A)=\int_Af(s)\mathrm ds
\end{aligned}
$$

### 连续型随机变量

<font color = yellow>定义 2.3.2</font> 如果随机变量 $X$ 有概率密度 $f(s)$, 则称 $X$ 是**连续型随机变量**.

连续型随机变量 $X$ 及其概率密度 $f(x)$ 有以下的基本性质:

1. $\int_{-\infty}^{\infty}f(x)\mathrm dx=1$
2. $P(X=a)=0\Rightarrow P(a\le X\le b)=P(a< X\le b)$
3. 对数集 $A$, $P(X\in A)=\int_Af(x)\mathrm dx$
4. $F(x)=\int_{-\infty}^xf(s)\mathrm ds$ 是连续函数

### 常见的连续型随机变量分布

#### 均匀分布 (Uniform)

对 $a<b$, 如果 $X$ 的概率密度为

$$
f(x)=\begin{cases}
\frac{1}{b-1}&x\in(a,b)\\
0&x\not\in(a,b)
\end{cases}
$$

则称 $X$ 服从区间 $(a,b)$ 上的均匀分布, 记作 $X\sim U(a,b)$.

#### 指数分布 (Exponential)

对常数 $\lambda>0$, 如果 $X$ 的概率密度为

$$
f(x)=\begin{cases}
\lambda\exp(-\lambda x)&x\ge0\\
0&x<0
\end{cases}
$$

则称 $X$ 服从参数为 $\lambda$ 的指数分布, 记作 $X\sim \mathrm{Exp}(\lambda)$.

> 如果随机变量 $X$ 满足 $P(X<0)=0$, 则称 $X$ 是**非负随机变量**.

<font color=green>定理 2.3.2</font> 设 $X$ 是连续型非负随机变量, 则 $X$ 服从指数分布的充分必要条件是对任何 $s,t\ge0$, 有

$$
P(X>s+t\vert X>s)=P(X>t)
$$

称上式的性质为**无后效性**或**无记忆性**, 它是指数分布的特征.

#### 正态分布 (Normal)

设 $\mu$ 是常数, $\sigma>0$ 是常数. 如果 $X$ 的概率密度是

$$
f(x)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
$$

则称 $X$ 服从参数为 $(\mu,\sigma^2)$ 的正态分布, 记作 $X\sim N(\mu,\sigma^2)$. 特别地, 当 $X\sim N(0,1)$ 时, 称 $X$ 服从**标准正态分布**. 标准正态分布的概率密度有着特殊的重要地位, 所以用一个特定的符号 $\varphi(x)$ 表示:

$$
\varphi(x)=f(x)=\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{x^2}{2}\right)\quad x\in\mathbb R
$$

正态分布概率密度有着以下的简单的性质:

1. $f(x)$ 关于 $x=\mu$ 对称
2. $f(\mu)=1/(\sqrt{2\pi}\sigma)$ 是最大值

对于随机变量 $X\sim N(\mu,\sigma^2)$, 有

$$
\frac{X-\mu}{\sigma}\sim N(0,1)
$$

而我们经常遇到求 $F(a)=P(X\le a)$ 的问题, 为了方便, 我们用

$$
\Phi(x)=\int_{-\infty}^{x}\varphi(s)\mathrm ds
$$

表示标准正态分布的分布函数, 则

$$
\begin{aligned}
&F(x)=\Phi\left(\frac{x-\mu}{\sigma}\right)\\
&P(a< X\le b)=\Phi\left(\frac{b-\mu}{\sigma}\right)-\Phi\left(\frac{a-\mu}{\sigma}\right)
\end{aligned}
$$

> 利用对称性, 易知 $\Phi(x)+\Phi(-x)=1$

#### 伽马分布 (Gamma)

设 $\alpha, \beta>0$ 是常数, 如果 $X$ 的概率密度是

$$
f(x)=\begin{cases}
\frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}\exp(-\beta x) & x\ge 0\\
0&x<0
\end{cases}
$$

则称 $X$ 服从参数是 $(\alpha, \beta)$ 的伽马分布, 记作 $X\sim\Gamma(\alpha,\beta)$.

## 随机变量函数的分布

> 开区间或开区间的并称为开集

<font color=green>定理 2.4.1</font> 如果开集 $D$ 使得 $P(X\in D)=1$, $g(x)$ 在 $D$ 中连续, 使得

$$
P(X=x)=g(x)\mathrm dx\quad x\in D
$$

则 $X$ 有概率密度

$$
f(x)=g(x)\quad x\in D
$$

设 $X$ 有概率密度 $f(x)$, 随机变量 $Y=h(X)$, 则有

$$
P(Y=y)=P(X=h^{-1}(y))=f(h^{-1}(y))\mathrm{d}(h^{-1}(y))=f(h^{-1}(y))\frac{1}{h'(y)}\mathrm{d}y
$$

那么 $Y$ 就有概率密度 $f_Y(y)=f(h^{-1}(y))\frac{1}{h'(y)}$

---

# 随机向量

## 随机向量的基本概念

<font color = yellow>定义 3.1.1</font> 如果 $X_1, X_2, \cdots, X_n$ 是定义在同一概率空间上的随机变量, 则 $\boldsymbol X=(X_1, X_2, \cdots, X_n)$ 是 $n$ 维随机向量, 简称为**随机向量**.

对于随机事件 $A_1,A_2, \cdots,A_n$, 用 $\{A_1,A_2, \cdots,A_n\}$ 表示 $\bigcap ^n_{j=1}A_j$, 于是有 $\{X_1\le x_1,X_2\le x_2, \cdots, X_n\le x_n\}=\bigcap_{j=1}^n\{X_j\le x_j\}$

<font color = yellow>定义 3.1.2</font> 对于随机向量 $(X_1, X_2, \cdots, X_n)$, 称

$$
F(x_1, x_2,\cdots, x_n) = P(X_1\le x_1,X_2\le x_2, \cdots, X_n\le x_n)
$$

为 $(X_1, X_2, \cdots, X_n)$ 的**联合分布函数**. ^dbcc30

> 联合分布函数 $F(x_1, x_2,\cdots, x_n)$ 是 $x_j$ 的单调递增函数.

因为 $\{X_j\le\infty\}$ 是必然事件, 所以对所有的 $1\le j\le n$, $X_j$ 有概率分布:

<font color = yellow>定义 3.1.3</font> 对于随机向量 $(X_1, X_2, \cdots, X_n)$, 有概率分布 $F(x_1, x_2,\cdots, x_n)$, 称

$$
F_j(x_j)=P(X_j\le x_j)=F(\infty, \cdots, \infty, x_j, \infty, \cdots, \infty)
$$

为 $(X_1, X_2, \cdots, X_n)$ 的**边缘分布函数**.

由此我们能定义随机变量的独立性:

<font color = yellow>定义 3.1.4.1</font> 如果 $\forall x,y\in\mathbb R$, 事件 $\{X\le x\}, \{Y\le y\}$, 独立, 则称随机变量 $X,Y$ 独立.

> $X,Y$ 独立的充分必要条件是 $P(X\le x,Y\le y)=P(X\le x)P(Y\le y)\Leftrightarrow F(x,y)=F_X(x)F_Y(y)$.

<font color = yellow>定义 3.1.4.2</font> 设 $X_1,X_2,\cdots$ 是随机变量,

1. 如果 $\forall x_1, x_2,\cdots, x_n$, 有 $P(X_1\le x_1,X_2\le x_2, \cdots, X_n\le x_n)=\prod_{j=1}^nP(X_j\le x_j)$, 则称随机变量 $(X_1, X_2, \cdots, X_n)$ 相互独立.
2. 如果 $\forall n\in\mathbb Z^+$, $X_1, X_2,\cdots,X_n$ 相互独立, 则称随机变量序列 $\{X_j\}=\{X_j\vert j=1,2,\cdots\}$ 相互独立.

> 常数与任何随机变量独立.

<font color=green>定理 3.1.1</font> 设 $X_1, X_2, \cdots, X_n$ 相互独立, 则有以下的结果:

1. 对于数集 $A_1, A_2, \cdots, A_n$, 事件 $\{X_1 \in A_1\},\{X_2 \in A_2\},\cdots,\{X_n \in A_n\}$ 相互独立
2. 对于一元函数 $g_1(x), g_2(x), \cdots, g_n(x)$, 随机变量 $Y_j=g_j(X_j)$ 相互独立.
3. 对于 $k$ 元函数 $g(x_1, x_2, \cdots, x_k)$, 记 $Z_k=g(X_1, X_2, \cdots, X_k)$, 则 $Z_k, X_{k+1}, X_{k+2}, \cdots, X_n$ 相互独立.

## 离散型随机向量

- 联合分布: $p_{ij}=P(X=x_i,Y=y_j)$
- 边缘分布: $p_i\equiv P(X=x_i), q_j\equiv P(Y=y_j)$

联合分布可以用表格表示如下

| $p_{ij}$  | $y_1$    | $y_2$    | $\cdots$ | $y_n$    | $\cdots$ | $\{p_i\}$ |
| --------- | -------- | -------- | -------- | -------- | -------- | --------- |
| $x_1$     | $p_{11}$ | $p_{12}$ | $\cdots$ | $p_{1n}$ | $\cdots$ | $p_1$     |
| $x_2$     | $p_{21}$ | $p_{22}$ | $\cdots$ | $p_{2n}$ | $\cdots$ | $p_2$     |
| $\vdots$  | $\vdots$ | $\vdots$ |          | $\vdots$ |          | $\vdots$  |
| $x_n$     | $p_{n1}$ | $p_{n2}$ | $\cdots$ | $p_{nn}$ | $\cdots$ | $p_n$     |
| $\vdots$  | $\vdots$ | $\vdots$ |          | $\vdots$ |          | $\vdots$  |
| $\{q_i\}$ | $q_1$    | $q_2$    | $\cdots$ | $q_n$    | $\cdots$ | $1$       |

<font color=green>定理 3.2.1</font> 离散型随机向量 $(X,Y)$ 的所有不同取值为 $(x_i,y_j),\ i,j\ge1$, 则 $X,Y$ 独立的充分必要条件为 $\forall (x_i,y_j), P(X=x_i, Y=y_j)=P(X=x_i)P(Y=y_j)$

> 设 $A_1, A_2, \cdots, A_r$ 是试验 $S$ 的完备事件组. 对试验 $S$ 进行 $n$ 次独立重复试验时, 用 $X_i$ 表示事件 $A_i$ 发生的次数, 则 $(X_1, X_2, \cdots, X_r)$ 的联合分布 (**多项分布**) 为
> $P(X_1=k_1, X_2=k_2, \cdots, X_r=k_r)=\frac{n!}{\prod_{i=1}^r k_i!}\prod_{i=1}^rp_i^{k_i}$
> 其中 $k_i\ge0,p_i=P(A_i), \sum_{i=1}^rk_i=n$

## 连续型随机向量

### 联合密度

<font color = yellow>定义 3.3.1</font> 设 $(X,Y)$ 是随机向量, 如果有 $\mathbb R^2$ 上的非负函数 $f(x,y)$ 使得 $\forall D=(a,b]\times(c,d]\in\mathbb R^2$, 有 $P((X,Y)\in D)=\iint_Df(x,y)\mathrm dx\mathrm dy$, 则称 $(X,Y)$ 是连续型随机向量, 并称 $f(x,y)$ 是 $(X,Y)$ 的**联合概率密度**或**联合密度**.

> 记示性函数为 $I[D]=I[(x,y)\in D]$, 那么 $P((X,Y)\in D)=\iint_Df(x,y)\mathrm dx\mathrm dy=\iint_{\mathbb R^2}f(x,y)I[D]\mathrm dx\mathrm dy$

### 边缘密度

对任何 $x$, 知道其边缘分布为

$$
P(X\le x)=P(X\le x,Y\le\infty)=\int^{x}_{-\infty}\left(\int_{-\infty}^{\infty}f(x,y)\mathrm d y \right)\mathrm dx
$$

那么可知 $X$ 有边缘密度函数

$$
f_X(x)=\int_{-\infty}^{\infty}f(x,y)\mathrm d y
$$

对称地可知 $Y$ 的边缘密度函数

$$
f_Y(y)=\int_{-\infty}^{\infty}f(x,y)\mathrm d x
$$

> 设 $D\in\mathbb R^2$, $m(D)$ 是 $D$ 的面积, 如果 $(X,Y)$ 有联合密度 $f(x,y)=\frac{1}{m(D)}I[D]$, 则称 $(X,Y)$ 在 $D$ 上均匀分布, 记作 $(X,Y)\sim U(D)$.

### 独立性

<font color=green>定理 3.3.1</font> 设 $X,Y$ 分别有概率密度 $f_X(x), f_Y(y)$. 则 $X,Y$ 独立的充分必要条件是随机向量 $(X,Y)$ 有联合密度

$$
f(x,y)=f_X(x)f_Y(y)
$$

<font color=green>定理 3.3.2</font> 设 $(X,Y)$ 是随机向量. 已知 $X=x$ 时, 如果 $Y$ 的取值范围和 $x$ 有关, 则 $X,Y$ 不独立.

<font color=green>定理 3.3.3</font> 若连续型随机向量 $(X_1, X_2,\cdots, X_n)$ 的概率密度函数 $f(x_1, x_2, \cdots, x_n)$ 可表示为 $n$ 个函数 $g_1, g_2, \cdots, g_n$ 之积, 其中 $g_i$ 只依赖于 $x_i$, 即

$$
f(x_1, x_2, \cdots, x_n)=\prod_{i=1}^ng_i(x_i)
$$

则 $X_1, X_2, \cdots, X_n$ 相互独立, 且 $X_i$ 的边缘密度函数 $f_i(x_i)$ 只与 $g_i(x_i)$ 只相差一个常数因子.

## 随机向量函数的分布

<font color=green>定理 3.4.1</font> (**全概率公式**) 如果随机变量 $X$ 有概率分布 $p_j=P(X=x_j), j\ge 0$, 则对事件 $B$ 有

$$
P(B)=\sum_{j=0}^\infty P(B\vert X=x_j)p_j
$$

### 离散型随机向量的函数

记随机向量 $Z=h(X,Y)$, 利用全概率公式和乘法公式, 则有

$$
P(Z=k)=\sum_{j=0}^\infty P(Z=k\vert X=x_j)P(X=x_j)=\sum_{j=0}^\infty P(h(x_j,y)=k)P(X=x_j)
$$

可推广到 $n$ 维随机向量, 这里不再赘述.

### 连续型随机向量的函数

记随机向量 $Z=h(X,Y)$, 利用全概率公式和乘法公式, 则有

$$
F_Z(z)=P(h(X,Y)\le z)=\iint_{h(x,y)\le z}f(x,y)\mathrm dx\mathrm dy
$$

则概率密度

$$
f_Z(z)=\frac{\mathrm d}{\mathrm dz}\iint_{h(x,y)\le z}f(x,y)\mathrm dx\mathrm dy
$$

可推广到 $n$ 维随机向量, 这里不再赘述.

以下是一个简单的例子:

| 随机向量的函数 | 离散型分布函数                                | 连续型概率密度                                    |
| -------------- | --------------------------------------------- | ------------------------------------------------- |
| $U=X+Y$        | $P(U=u)=\sum_{i=-\infty}^\infty P(X=i,Y=u-i)$ | $f_U(u)=\int_{-\infty}^\infty f(x,u-x)\mathrm dx$ |
| $V=X-Y$        | $P(V=v)=\sum_{i=-\infty}^\infty P(X=i,Y=i-u)$ | $f_V(v)=\int_{-\infty}^\infty f(x,x-v)\mathrm dx$ |

## 随机向量函数的密度

<font color=green>定理 3.5.1</font> 如果平面上的开集 $D$ 使得 $P((X,Y)\in D)=1$ 且 $D$ 中连续函数 $g(x,y)$ 使得

$$
P(X=x, Y=y)=g(x,y)\mathrm dx\mathrm dy\quad (x,y)\in D
$$

则 $f(x,y)=g(x,y)I[D]$ 是 $(X,Y)$ 的联合密度.

设随机向量 $(X,Y)$ 有密度 $f_{X,Y}(x,y)$, 随机向量 $(U,V)=(u(X,Y), v(X,V))$, 那么, 设反解出 $X=x(U,V), Y=y(U,V)$, 那么就有:

$$
\begin{align*}
&P(U=u,V=v)=f_{U,V}(u,v)\mathrm du\mathrm dv\\
=&P(X=x(u,v),Y=y(u,v))=f_{X,Y}(x(u,v), y(u,v))\mathrm dx\mathrm dy
\end{align*}
$$

如果 $x(u,v), y(u,v)$ 有连续的偏导数, 且 Jacobi 行列式

$$
J=\frac{\partial(x,y)}{\partial(u,v)}=\left\lvert
\begin{matrix}
\frac{\partial x}{\partial u}&\frac{\partial x}{\partial v}\\
\frac{\partial y}{\partial u}&\frac{\partial y}{\partial v}
\end{matrix}
\right\rvert\not=0
$$

则有 $\mathrm dx\mathrm dy=\lvert J\rvert\mathrm du\mathrm dv$, 那么得到 $(U,V)$ 的概率密度为

$$
f_{U,V}(u,v)=f_{X,Y}(x(u,v), y(u,v))\left\lvert\frac{\partial(x,y)}{\partial(u,v)}\right\rvert
$$

## 二维正态分布

如果 $Y_1,Y_2$ 独立, 都服从标准正态分布 $N(0,1)$, 则 $\boldsymbol Y=(Y_1,Y_2)$ 有联合密度

$$
\varphi (y_1, y_2)=\frac{1}{2\pi}\exp\left(-\frac{y_1^2+y_2^2}{2}\right)
$$

这时称 $\boldsymbol Y=(Y_1,Y_2)$ 服从**二维标准正态分布**, 记作 $\boldsymbol Y\sim N(\boldsymbol 0,\boldsymbol I)$.

设 $\boldsymbol Y=(Y_1,Y_2)\sim N(\boldsymbol 0,\boldsymbol I)$, $ad-bc\not=0$. 定义

$$
\begin{cases}
X_1=aY_1+bY_2+\mu_1\\
X_2=cY_1+dY_2+\mu_2
\end{cases}
$$

则称 $(X_1,X_2)$ 服从二维正态分布.

引入 $\sigma_1=\sqrt{a^2+b^2}, \sigma_2=\sqrt{c^2+d^2}, \rho=\frac{ac+bd}{\sigma_1\sigma_2}$, 则可以把 $\boldsymbol X=(X_1,X_2)$ 的联合密度写成

$$
\small f(x_1,x_2)=\frac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}}\exp\left\{-\frac{1}{2(1-\rho^2)}\left[\frac{(x_1-\mu_1)^2}{\sigma_1^2}-\frac{2\rho(x_1-\mu_1)(x_2-\mu_2)}{\sigma_1\sigma_2}+\frac{(x_2-\mu_2)^2}{\sigma_2^2}\right]\right\}
$$

因为只有 5 个参数 $\mu_1,\mu_2;\sigma_1^2,\sigma_2^2;\rho$, 所以又称 $(X_1,X_2)$ 服从参数为 $(\mu_1,\mu_2;\sigma_1^2,\sigma_2^2;\rho)$ 的正态分布, 记作 $(X_1,X_2)\sim N(\mu_1,\mu_2;\sigma_1^2,\sigma_2^2;\rho)$

<font color=green>定理 3.6.1</font> $(X_1,X_2)\sim N(\mu_1,\mu_2;\sigma_1^2,\sigma_2^2;\rho)$, 则

1. $X_1\sim N(\mu_1,\sigma_1^2), X_2\sim N(\mu_2,\sigma_2^2)$
2. $X_1,X_2$ 独立的充分必要条件是 $\rho=0$
3. 当 $a_1a_4-a_2a_3\not=0$, 随机向量 $(a_1X_1+a_2X_2+c_1,a_3X_1+a_4X_2+c_2)$ 服从二维正态分布.
4. 线性组合 $Z=a_1X_1+a_2X_2+c_1$ 服从正态分布
5. 若 $Z_1,Z_2$ 相互独立且都服从正态分布, 则 $(Z_1,Z_2)\sim N(\mu_{Z_1},\mu_{Z_2};\sigma_{Z_1}^2,\sigma_{Z_2}^2;0)$

以下是三个推论:

- 设 $\boldsymbol Y=(Y_1,Y_2)\sim N(\boldsymbol 0,\boldsymbol I)$, $X_1=Y_1+bY_2, X_2=-bY_1+Y_2$, 则 $X_1,X_2$ 独立且都满足 $N(0,1+b^2)$
- 设 $\boldsymbol Y=(Y_1,Y_2)\sim N(\boldsymbol 0,\boldsymbol I)$, 则 $X=aY_1+bY_2+c$ 服从正态分布.
- 若 $X\sim N(\mu_1,\sigma_1^2), Y\sim N(\mu_2, \sigma_2^2)$ 独立, $a\not=0$, 则线性组合 $U=aX+bY+c$ 服从正态分布.

## 条件密度

> 我们称 $P(B\vert A)$ 是 $B\vert A$ 的概率. 类似地, 我们可以对条件概率分布给出定义.

### 离散型

<font color = yellow>定义 3.7.1</font> 设随机变量 $X$ 的取值为 $x_1, x_2,\cdots$, 则称

$$
h_j=P(X=x_j\vert A)
$$

为 $X\vert A$ 的概率分布.

依照条件概率的计算公式, 我们给出离散型的条件概率分布公式:

<font color=green>定理 3.7.1</font> 设 $(X,Y)$ 是离散型随机向量, 有联合分布 $p_{ij}$ 和边缘分布 $p_i,q_j$, 那么有条件概率分布

$$
\begin{aligned}
&P(X=x_i\vert Y=y_j)=\frac{p_{ij}}{q_j}\\
&P(Y=y_j\vert X=x_i)=\frac{p_{ij}}{p_i}
\end{aligned}
$$

### 连续型

假设 $F(x,y)$ 有连续的偏导数, 则 $(X,Y)$ 是连续型随机向量, 有联合密度

$$
f(x,y)=\frac{\partial^2}{\partial x\partial y}F(x,y)
$$

得到 $Y$ 的边缘密度

$$
f_Y(y)=\int_{-\infty}^\infty f(x,y)\mathrm dx
$$

对于 $f_Y(y)>0$ 的情况, 我们有

$$
P(X=x\vert Y=y)=\frac{P(X=x,Y=y)}{P(Y=y)}=\frac{f(x,y)\mathrm dx\mathrm dy}{f_Y(y)\mathrm dy}=\frac{f(x,y)}{f_Y(y)}\mathrm dx
$$

即得到了条件密度, 如下.

<font color = yellow>定义 3.7.2</font> 设随机向量 $(X,Y)$ 有联合密度 $f(x,y)$, $Y$ 有边缘密度 $f_Y(y)$. 如果在 $y$ 处 $f_Y(y)>0$, 则称

$$
F_{X\vert Y}(x\vert y)=P(X\le x\vert Y\le y)=\int_{-\infty}^x\frac{f(s,y)}{f_Y(y)}\mathrm ds\quad x\in\mathbb R
$$

为 $X\vert\{Y=y\}$ 的分布函数, 简称为**条件分布函数**.
称 ^6bc670

$$
f_{X\vert Y}(x\vert y)=\frac{f(x,y)}{f_Y(y)}\quad x\in\mathbb R
$$

为 $X\vert\{Y=y\}$ 的概率密度, 简称为**条件密度**.

根据上面的分析, 有条件密度公式

$$
f_{X\vert Y}(x\vert y)=\frac{\frac{\partial^2}{\partial x\partial y}F(x,y)}{\int_{-\infty}^\infty\frac{\partial^2}{\partial x\partial y}F(x,y)\mathrm dx}
$$

> 容易看出 $X,Y$ 独立的条件为 $F_{X\vert Y}(x\vert y)=F_X(x)$ 或 $f_{X\vert Y}(x\vert y)=f_X(x)$ 对所有的 $x,y$ 成立.

<font color=green>定理 3.7.2</font> 如果 $(X,Y)\sim N(\mu_1,\mu_2;\sigma_1^2,\sigma_2^2;\rho)$, 则 $X\vert \{Y=y\}\sim N(\mu_y,\sigma_y^2)$, 其中

$$
\mu_y=\mu_1+\rho\frac{\sigma_1}{\sigma_2}\mu_2\qquad\sigma_y^2=(1-\rho^2)\sigma_1^2
$$

---

# 随机变量的数字特征

## 随机变量的数学期望

<font color = yellow>定义 4.1.1</font> 设 $X$ 有概率分布 $p_j=P(X=x_j), j = 0,1, \cdots$, 如果有 $\displaystyle \sum^{\infty}_{j=0}|x_j|p_j<\infty$, 则称 $X$ 的数学期望存在, 并且称 $\displaystyle E(X) = \sum^{\infty}_{j=0}|x_j|p_j$ 为 $X$ 或分布 $\{p_j\}$ 的**数学期望**.

<font color = yellow>定义 4.1.2</font> 设 $X$ 有概率密度 $f(x)$, 如果有 $\displaystyle \int^\infty_{-\infty}xf(x)\mathrm{d}x<\infty$, 则称 $X$ 的数学期望存在, 并且称 $\displaystyle E(X) = \int^\infty_{-\infty}xf(x)\mathrm{d}x$ 为 $X$ 或 $f(x)$ 的**数学期望**.

### 常用的数学期望

<font color=green>定理 4.1.1</font> 设 $X$ 的数学期望有限, 概率密度 $f(x)$ 关于 $c$ 对称 $\Leftrightarrow\ f(c+x)=f(c-x)$, 则 $E(X) = c$.

- 伯努利分布 $B(1,p)$ 与二项分布 $B(n,p)$

$$
X\sim B(1,p) \Rightarrow E(X)=p\quad X\sim B(n,p) \Rightarrow E(X)=np
$$

- 泊松分布 $P(\lambda)$

$$
X\sim P(\lambda) \Rightarrow E(X)=\lambda
$$

- 几何分布 $P(X=j)=p(1-p)^{j-1}$

$$
E(X)=\frac{1}{p}
$$

- 指数分布 $\mathrm{Exp}(\lambda)$

$$
E(X)=\frac{1}{\lambda}
$$

- 均匀分布 $U(a,b)$

$$
E(X)=\frac{a+b}{2}
$$

- 正态分布 $N(\mu,\sigma^2)$

$$
E(X)=μ
$$

### 数学期望的计算

<font color=green>定理 4.1.2</font> 设 $X,Y$ 为离散型随机变量, $E(g(X)), E(h(X,Y))$ 存在.

1.  若 $X$ 有离散分布 $p_j=P(X=x_j), j\ge 1$, 则 $\displaystyle E(g(X)) = \sum^{\infty}_{j=1}g(x_j)p_j$.
2.  若 $X,Y$ 有离散分布 $p_{ij}=P(X=x_j, Y=y_j), i,j\ge 1$, 则$$E(h(X,Y)) = \sum^{\infty}_{i,j=1}h(x_i,y_j)p_{ij}$$

> <font color = red>例 4.1.1</font> > $\displaystyle X\sim B(n,p), E[X(X-1)] = \sum^n_{j=0}j(j-1)\mathrm{C}^j_np^j(1-p)^{n-j}=p^2\left.\left(\frac{\mathrm{d}^2}{\mathrm dx^2}\sum^n_{j=0}\mathrm{C}^j_nx^j(1-p)^{n-j}\right)\right|_{x=p}=p^2\left.\frac{\mathrm{d}^2}{\mathrm dx^2}(x+q)^n\right|_{x=p}=n(n-1)p^2$

<font color=green>定理 4.1.3</font> 设 $X,Y$ 为连续型随机变量, $E(g(X)), E(h(X,Y))$ 存在.

1.  若 $X$ 有概率密度 $f(x)$, 则 $\displaystyle E(g(X)) = \int_{-\infty}^\infty g(x)f(x)\mathrm{d}x$.
2.  若 $X,Y$ 有概率密度 $f(x,y)$, 则 $\displaystyle E(h(X,Y)) = \iint_{\mathbb{R}^2} h(x,y)f(x,y)\mathrm{d}x\mathrm{d}y$.
3.  若 $X$ 是非负随机变量, 则 $\displaystyle E(X) = \int_{0}^\infty P(X>x)\mathrm{d}x$.

> <font color=red>例 4.1.2</font> $\displaystyle X\sim U(0,\frac{\pi}{2}), E(\cos X) = \int_0^{\pi/2}\frac{2}{\pi}\cos x\mathrm dx=\frac{2}{\pi}$

### 数学期望的性质

<font color=green>定理 4.1.4</font> 设 $E(X_j)<\infty (1\le j\le n)$, $c_0, c_1, \cdots c_n$ 是常数, 则有

1.  线性组合 $Y = c_0 + c_1X_1 + c_2X_2 +\cdots + c_nX_n$ 的数学期望存在, 而且有 $E(Y) = c_0 + \sum^n_{j=1}c_jE(X_j)$
2.  如果 $X_1, X_2, \cdots, X_n$ 相互独立, 则乘积 $Z = X_1X_2\cdots X_n$ 的数学期望存在, 而且有 $E(Z) = \prod_{j=1}^nE(X_j)$
3.  如果 $P(X_1\le X_2) = 1$, 则 $E(X_1)\le E(X_2)$

<font color=green>定理 4.1.5</font> $E(|X|)=0$ 的充分必要条件是 $P(X=0)=1$
此时我们称 $X=0$ **以概率 1 发生**, 记作 $X=0\ a.s.$ . 以概率 1 发生又被称作几乎处处或几乎必然 (almost surely) 发生.

## 随机变量的方差

<font color = yellow>定义 4.2.1</font> 设 $\mu=E(X)$, 如果 $E\left((X-\mu)^2\right)<\infty$ , 则称 $\sigma^2=E\left((X-\mu)^2\right)$ 为 $X$ 的**方差**, 记作 $Var(X)$ 或 $\sigma_X^2$. 称 $\sigma_X=\sqrt{Var(X)}$ 为 $X$ 的**标准差**.

- 当 $X$ 有离散分布 $p_j=P(X=x_j), j=1,2,\cdots$ 时, 有

$$
Var(X) = E\left((X-\mu)^2\right)=\sum^\infty_{j=1}(x_j-\mu)^2p_j
$$

- 当 $X$ 有概率密度 $f(x)$ 时, 有

$$
Var(X) = E\left((X-\mu)^2\right)=\int^\infty_{-\infty}(x-\mu)^2f(x)\mathrm dx
$$

说明随机变量 $X$ 的方差由 $X$ 的概率分布唯一决定, 即

<font color = green>定理 4.2.1</font> 如果 $X,Y$ 有相同的概率分布, 则它们有相同的数学期望和方差

> $X$ 的方差描述了 $X$ 的分散程度, $Var(X)$ 越小, 说明 $X$ 在数学期望附近越集中. 特别地, $Var(X) = 0\Leftrightarrow X=\mu\ a.s.$

利用方差的定义有

$$
Var(X)=E\left((X-\mu)^2\right)=E\left(X^2-2X\mu+\mu^2\right)=E\left(X^2\right)-E^2(X)
$$

这就是计算方差的常用公式.

### 常用的方差

- 伯努利分布 $B(1,p)$ 与二项分布 $B(n,p)$

$$
\begin{aligned}
&E(X) = np, E\left(X(X-1)\right)=n(n-1)p^2\Rightarrow E\left(X^2\right)=n(n-1)p^2+np\\
&Var(X)=n(n-1)p^2+np-(np)^2=np(1-p)
\end{aligned}
$$

- 泊松分布 $P(\lambda)$

$$
\begin{aligned}
E\left(X^2\right)&=E\left(X(X-1)\right)+E(X)\\
&=\sum_{k=0}^\infty k(k-1)\frac{\lambda^k}{k!}\exp(-\lambda)+\lambda\\
&=\lambda^2\sum_{k=2}^\infty \frac{\lambda^{k-2}}{(k-2)!}\exp(-\lambda)+\lambda\\
&=\lambda^2+\lambda
\end{aligned}
\Rightarrow Var(X)=\lambda
$$

- 几何分布 $P(X=j)=p(1-p)^{j-1}$

$$
\begin{aligned}
&\begin{aligned}
E\left(X^2\right)&=E\left(X(X-1)\right)+E(X)\\
&=\sum_{k=0}^\infty k(k-1)p(1-p)^{k-1}+\frac{1}{p}\\
&=p(1-p)\frac{\mathrm d^2}{\mathrm d(1-p)^2}\left(\sum_{k=0}^\infty(1-p)^k\right)+\frac{1}{p}\\
&=p(1-p)\frac{\mathrm d^2}{\mathrm d(1-p)^2}\left(\frac{1}{1-(1-p)}\right)+\frac{1}{p}\\
&=\frac{2p(1-p)}{p^3}+\frac{1}{p}\\
&=\frac{2(1-p)}{p^2}+\frac{1}{p}
\end{aligned}\\
&\Rightarrow Var(X)=\frac{2(1-p)}{p^2}+\frac{1}{p}-\frac{1}{p^2}=\frac{1-p}{p^2}
\end{aligned}
$$

- 指数分布 $\mathrm{Exp}(\lambda)$

$$
\begin{aligned}
E\left(X^2\right)&=\int^\infty_0x^2\lambda \exp(-\lambda x)\mathrm dx\\
&= \frac{1}{\lambda^2}\int^\infty_0t^2\exp(-t)\mathrm dt\\
&= \frac{1}{\lambda^2}\Gamma(3)\\
&= \frac{2}{\lambda^2}
\end{aligned}
\Rightarrow Var(X)=\frac{2}{\lambda^2}-\frac{1}{\lambda^2}=\frac{1}{\lambda^2}
$$

- 均匀分布 $U(a,b)$

$$
E\left(X^2\right)=\int_a^b\frac{x^2}{b-a}\mathrm dx=\frac{b^3-a^3}{3(b-a)}\Rightarrow Var(x)=\frac{b^3-a^3}{3(b-1)}-\left(\frac{a+b}{12}\right)^2=\frac{(b-a)^2}{12}
$$

- 正态分布 $N(\mu,\sigma^2)$

$$
Var(X)=\sigma^2
$$

### 方差的性质

<font color=green>定理 4.2.2</font> 设 $a,b,c$ 是常数, $E(X)=\mu, Var(X)<\infty$, $E(X_j)=\mu_j, Var(X_j)<\infty (1\le j\le n)$, 则有

1.  $Var(a+bX)=b^2Var(X)$
2.  $\forall c\neq \mu, Var(X)=E\left((X-\mu)^2\right) <E\left((X-c)^2\right)$
3.  $Var(X)=0\Leftrightarrow P(X=\mu)=1$
4.  当 $X_1, X_2, \cdots, X_n$ 相互独立时, $Var\left(\sum_{j=1}^nX_j\right)=\sum_{j=1}^nVar(X_j)$

设 $X\sim N(\mu,\sigma^2), Y=\frac{X-\mu}{\sigma}$, 则 $E(Y)=0, Var(Y)=1$, 这时称 $Y$ 为 $X$ 的**标准化**.

## 协方差和相关系数

### 内积不等式

<font color=green>定理 4.3.1</font> 设 $E\left(X^2\right)<\infty,E\left(Y^2\right)<\infty$, 则有 $|E(XY)|\le \sqrt{E\left(X^2\right)E\left(Y^2\right)}$, 其中等号成立的充分必要条件是有不全为零的常数 $a,b$ 使得 $P(aX+bY=0)=1$

### 协方差和相关系数

<font color = yellow>定义 4.3.1</font> 设 $\mu_X=E(X), \mu_Y=E(Y), \sigma_X=\sqrt{Var(X)}, \sigma_Y=\sqrt{Var(Y)}$.

1.  当 $\sigma_X,\sigma_Y$ 存在时, 称 $E((X-\mu_X)(Y-\mu_Y))$ 为随机变量 $X,Y$ 的**协方差**, 记作 $Cov(X,Y)$, 或 $\sigma_{XY}$. 当 $Cov(X,Y)=0$ 时, 称 $X,Y$ **不相关**. ^7b48f1
2.  当 $0<\sigma_X\sigma_Y<\infty$ 时, 称 $\rho_{XY}=\frac{\sigma_{XY}}{\sigma_X\sigma_Y}$ 为 $X,Y$ 的**相关系数**, $\rho_{XY}$ 也常用 $\rho(X,Y)$ 表示.

类似计算方差的常用公式, 我们有以下计算协方差的常用公式:

$$
Cov(X,Y)=E(XY)-E(X)E(Y)
$$

利用内积不等式和相关系数的定义, 我们有以下性质

<font color=green>定理 4.3.2</font> 设 $\rho_{XY}$ 是 $X,Y$ 的相关系数, 则有

1.  $|\rho_{XY}|\le 1$
2.  $|\rho_{XY}|= 1\Leftrightarrow \exists a,b, s.t.\ P(Y=a+bX)=1$
3.  如果 $X,Y$ 独立, 则 $X,Y$ 不相关.

- 可以看出, $|\rho_{XY}|= 1$ 时, $X,Y$ 有线性关系, 这时称 $X,Y$ **线性相关**.
- 相关系数只表示了随机变量之间的线性关系, 相关系数为零时两随机变量之间也可以有其他非线性关系, 比如 $X\sim N(0,1), Cov\left(X,X^2\right)=E\left(X^3\right)-E(X)=0\Rightarrow\rho\left(X,X^2\right)=0$.

### 协方差矩阵

<font color = yellow>定义 4.3.1</font> 称随机向量 $(X_1,X_2)$ 的协方差 $\sigma_{ij}=Cov(X_i,X_j)$ 构成的矩阵

$$
\Sigma=\left(
\begin{matrix}
\sigma_{11}&\sigma_{12}\\
\sigma_{21}&\sigma_{22}
\end{matrix}
\right)
$$

为 $X$ 的**协方差矩阵**. 因为 $\sigma_{12}=\sigma_{21}$, 所以协方差矩阵 $\Sigma$ 是对称矩阵.

<font color=green>定理 4.3.3</font> 设 $\boldsymbol X=(X_1, X_2)$ 有协方差矩阵 $\Sigma$, $E(\boldsymbol X)=(\mu_1,\mu_2)$, 则

1.  $\Sigma$ 是正半定矩阵
2.  $\Sigma$ 退化的充分必要条件是有不全为零的常数 $a_1, a_2$ 使得

$$
P\left(\sum_{i=1}^2a_i(X_i-\mu_i)=0\right)=1
$$

## 正态分布的参数计算

设 $Y_1, Y_2\sim N(0,1)$ 独立, $ac-bd\neq0$ 且

$$
\begin{cases}
X_1=aY_1+bY_2+\mu_1\\
X_2=cY_1+dY_2+\mu_2
\end{cases}
$$

则

$$
Cov(X_1,X_2)=ac+bd,(X_1,X_2)\sim N(\mu_1, \mu_2;\sigma_1^2, \sigma_2^2; \rho)
$$

其中有

$$
\sigma_1^2=a^2+b^2, \sigma_2^2=c^2+d^2, \rho=\frac{ac+bd}{\sigma_1\sigma_2}
$$

容易计算得到 $X_1, X_2$ 的数字特征

$$
\begin{cases}
E(X_1)=\mu_1 & E(X_2) = \mu_2\\
Var(X_1)=\sigma_1^2 & Var(X_2)= \sigma_2^2\\
\rho_{X_1X_2}=\rho
\end{cases}
$$

<font color=green>定理 4.4.1</font> 如果 $(X_1,X_2)\sim N(\mu_1, \mu_2;\sigma_1^2, \sigma_2^2; \rho)$, 则 $X_1, X_2$ 的数字特征如上式, 且 $X_1, X_2$ 独立的充分必要条件是 $X_1, X_2$ 不相关

---

# 大数定律和中心极限定理

## 强大数律

<font color = yellow>定义 4.1.1</font> 我们用 $A\ a.s.$ 表示 $P(A)=1$, 即

$$
P(A)=1\Leftrightarrow A\ a.s.
$$

<font color=green>定理 4.1.1</font> (强大数律) 如果 $X_1,X_2. \cdots$ 是独立同分布的随机变量, $\mu=E(X_1)$, 则

$$
\overline{X_n}=\frac{1}{n}\sum^n_{j=1}X_j, \lim_{n\to\infty}\overline{X_n}=\mu\ a.s.
$$

因为概率等于 1 的事件在实际中必然发生, 所以在强大数律中, 如果用 $x_n$ 表示 $X_n$ 的观测值, 则有

$$
\lim_{n\to\infty}\frac{x_1+x_2+\cdots+x_n}{n}=\mu
$$

> 因为强大数律的数学证明不需要概率的频率定义, 所以它从理论上保证了概率的频率定义是正确的.

## 弱大数律

有强大数律, 自然就有弱大数律. 为了介绍弱大数律, 先介绍随机变量的**依概率收敛**和**切比雪夫不等式**.

<font color = yellow>定义 4.2.1</font> 设 $U, U_1, U_2, \cdots$ 是随机变量. 若 $\forall\varepsilon>0, \lim_{n\to\infty}P(\lvert U_n-U\rvert\ge\varepsilon)=0$, 则称 $U_n$ 依概率收敛到 $U$, 记作 $U_n\xrightarrow{P}U$.

<font color=green>引理 4.2.1</font> (**切比雪夫不等式**) 设随机变量 $X$ 有数学期望 $\mu$ 和方差 $\sigma^2$, 则对常数 $\varepsilon>0$, 有

$$
P(\lvert X-\mu\rvert\ge\varepsilon)\le\frac{\sigma^2}{\varepsilon^2}
$$

---

**证明:** 记 $I[A]$ 为事件 $A$ 的示性函数, $Y=\lvert X-\mu\rvert$, 则无论 $\{Y\ge\varepsilon\}$ 是否发生, 总有

$$
I[\{Y\ge\varepsilon\}]\le\frac{Y^2}{\varepsilon^2}
$$

因此

$$
\begin{aligned}
P(\lvert X-\mu\rvert\ge\varepsilon)&=P(Y\ge\varepsilon)=E(I[\{Y\ge\varepsilon\}])\\
&\le E\left(\frac{Y^2}{\varepsilon^2}\right)=\frac{E(Y^2)}{\varepsilon^2}=\frac{\sigma^2}{\varepsilon^2}
\end{aligned}
$$

---

> 切比雪夫不等式是概率论中最重要和最基本的不等式.

<font color=green>推论 4.2.2</font> (**弱大数律**) 设随机变量 $X_1, X_2, \cdots$ 独立同分布, $\mu=E(X_1)$, 则对任何 $\varepsilon>0$, 有

$$
\lim_{n\to\infty} P\left(\lvert\overline{X_n}-\mu\rvert\ge\varepsilon\right)=0
$$

## 中心极限定理

> 强大数律和弱大数律分别讨论了随机变量的样本均值的几乎处处收敛和依概率收敛. 中心极限定律研究当 $n$ 比较大时, 随机变量的部分和 $S_n=\sum^n_{j=1}X_j$ 的概率分布问题.

独立同分布随机变量和的分布近似于正态分布.

<font color=green>定理 4.3.1</font> (**中心极限定理**) 设随机变量 $X_1, X_2, \cdots$ 独立同分布, $E(X_1)=\mu, Var(X_1)=\sigma^2>0$. 记 $S_n=\sum^n_{j=1}X_j$ 为部分和, $Z_n=\frac{S_n-n\mu}{\sqrt{n\sigma^2}}$ 为 $S_n$ 的标准化, $\Phi(x)$ 表示服从 $N(0,1)$ 的分布函数. 当 $n\to\infty$ 时, 有

$$
P(Z_n\le x)\to\Phi(x), x\in\mathbb R
$$

称 $Z_n$ 依概率收敛到 $N(0,1)$, 记作 $Z_n\xrightarrow d N(0,1)$. ^863a17

注意, 样本均值 $\overline{X_n}$ 的标准化等于部分和 $S_n$ 的标准化:

$$
Z_n=\frac{S_n-n\mu}{\sqrt{n\sigma^2}}=\frac{\overline{X_n}-\mu}{\sqrt{\sigma^2/n}}
$$

<font color=green>推论 4.3.2</font> 在定理 4.3.1 的条件下, 对较大的 $n$, 有

$$
\begin{aligned}
P\left(\frac{S_n-n\mu}{\sqrt{n\sigma^2}}\le x\right)\approx\Phi(x)\\
P\left(\frac{\overline{X_n}-\mu}{\sqrt{\sigma^2/n}}\le x\right)\approx\Phi(x)
\end{aligned}
$$

其中不知道方差时, 可以用样本方差

$$
\hat\sigma^2=\frac{1}{n-1}\sum^n_{j=1}\left(X_j-\overline{X_n}\right)^2\quad\mathrm{或}\quad\hat\sigma^2=\frac{1}{n}\sum^n_{j=1}\left(X_j-\overline{X_n}\right)^2
$$

代替 $\sigma^2$.
